---
title: "Assignment 3: Bayesian Analysis  \nLighthouse Problem\n"
author: "Shane Weisz (WSZSHA001)"
date: "19/09/2019"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
header-includes: \usepackage{float} \makeatletter\renewcommand*{\fps@figure}{H}\makeatother
---
This assignment involves the use of Bayesian Analysis methods to solve 'The Lighthouse Problem', where we attempt to draw inference on the coordinates of a lighthouse at an unknown location in the sea given a series of flashes emitted by the lighthouse that are observed at different points on the coastline.

## (i) Derivation of posterior distribution of $\alpha,\beta|x$

We want to derive the posterior distribution of $\alpha,\beta|\boldsymbol{x}$, which can be expressed as:
$$\pi(\alpha,\beta|\boldsymbol{x}) = \frac{\pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x})}{m(\boldsymbol{x})}= \frac{g(\alpha,\beta;\boldsymbol{x})}{m(\boldsymbol{x})},$$ where 
$g(\alpha,\beta;\boldsymbol{x})=\pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x})$.

#### Prior: $\pi(\alpha,\beta)$

From the context of the problem, we can make the assumption that $\alpha$ and $\beta$ are independent. As such, we can obtain our prior distribution from $$\pi(\alpha,\beta)=\pi(\alpha)\pi(\beta)$$. 

We are given that $\alpha \sim \text{U}(0,5)$ and $\beta \sim \text{Gamma}(4,8)$, and so substituting the appropriate density functions yields our **prior distribution**: $$\pi(\alpha,\beta)=\pi(\alpha)\pi(\beta) = \frac{1}{5}\frac{8^4 \beta^3 e^{-8\beta}}{\Gamma(4)}=\frac{2048\beta^3 e^{-8\beta}}{15}$$

#### Likelihood: $\text{L}(\alpha,\beta$;$\boldsymbol{x}$)

We first note that we calculate the likelihood as follows:
$$\text{L}(\alpha,\beta, \boldsymbol{x})=\prod_{i=1}^{200} f(x_i|\alpha,\beta)$$

We thus need to calculate the density function for the data, $f(x_i|\alpha,\beta)$. 
So let $\theta_i$ be the angle of inclination of the line joining the lighthouse to the point on the coastline where the $i^{th}$ emission was recorded. It follows that $\tan(\theta_i)=\frac{x_i-\alpha}{\beta}$ and hence that $\theta_l=-\arctan(\frac{\alpha}{\beta})<\theta_k<\arctan(\frac{5-\alpha}{\beta})=\theta_u$.

Now the problem definition allows us to make the assumption that $\theta_i \sim\text{U}(\theta_l,\theta_u)$, which yields the p.d.f. of $\theta_i$ as $\pi(\theta_i)=\frac{1}{\theta_u-\theta_l}=\frac{1}{\text{A}(\alpha,\beta)}$, where we define $\text{A}(\alpha,\beta) = \theta_u-\theta_l$.

Applying an appropriate univariate transformation, we obtain that $f(x_i|\alpha,\beta)=\frac{1}{\text{A}(\alpha,\beta)}\begin{vmatrix}\frac{d \theta_i}{d {x_i}}\end{vmatrix}$ where $\frac{d \theta_i}{d {x_i}}=\frac{d}{d {x_i}}\arctan(\frac{x_i-\alpha}{\beta})=\frac{\beta}{\beta^2+(x_k-\alpha)^2}$
Since $\beta>0$, we get that $\frac{\beta}{\beta^2+(x_k-\alpha)^2}>0$, and so  $f(x_i|\alpha,\beta)=\frac{1}{\text{A}(\alpha,\beta)}\cdot\frac{\beta}{\beta^2+(x_i-\alpha)^2}$.

Substituting into the above formula for the likelihood gives us our **likelihood** function:
$$\text{L}(\alpha,\beta, \boldsymbol{x})=\prod_{i=1}^{200} f(x_i|\alpha,\beta) = \prod_{i=1}^{200} \frac{1}{\text{A}(\alpha,\beta)}\cdot\frac{\beta}{\beta^2+(x_i-\alpha)^2}$$

#### Predictive pdf of x: $m(\boldsymbol{x})$

By the Law of Total Probability, we have that $$m(\boldsymbol{x})=\int_{0}^5 \int_{0}^{\infty} \pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x}) d\beta d\alpha$$ where $\pi(\alpha,\beta)=\frac{2048\beta^3 e^{-8\beta}}{15}$ and $\text{L}(\alpha,\beta, \boldsymbol{x})= \prod_{i=1}^{200} \frac{1}{\text{A}(\alpha,\beta)}\cdot\frac{\beta}{\beta^2+(x_i-\alpha)^2}$

## (ii) Function to calculate g($\alpha$,$\beta$;x) and obtain contour plot


```{r loadData, include=FALSE}
load("~/Documents/UCT/3rd Year/STA3043S/Assignments/Assignment3/Assignment3Data2019.RData")
x_data = Data['wszsha001',]
```

The following functions below are used to calculate g($\alpha$,$\beta$;x), by means of helper functions A and L.

```{r gfunc}
# A(alpha, beta) is defined as the difference between the upper and lower bounds for theta
A = function(alpha, beta)
{
   return( (atan((5 - alpha) / beta)) - (-atan(alpha / beta)) )
}

# Returns the likelihood function for alpha and beta given an observed data vector x
L = function(alpha, beta, x)
{
   return( prod( (1 / A(alpha, beta)) * beta / (beta ^ 2 + (x - alpha)^2)) )
}

# Returns g(alpha,beta;x) - the numerator of the posterior
gfunc = function(alpha, beta, x)
{
    prior_alpha = dunif(alpha, min = 0, max = 5)
    prior_beta  = dgamma(beta, shape = 4, rate = 8)
    return( prior_alpha * prior_beta * L(alpha, beta, x) )
}
gfunc.vec = Vectorize(gfunc, vectorize.args = c("alpha","beta"))
```

We use the above function to obtain the following Contour Plot of the joint posterior distribution of the
two parameters with the $\alpha$-axis ranging between (0, 5) and the $\beta$-axis ranging between (0, 1).

```{r contourPlot, echo=FALSE, fig.cap="Contour Plot"}
n = 100
alpha_range = seq(from = 0, to = 5, length.out = n)
beta_range  = seq(from = 0, to = 1, length.out = n)
g = outer(alpha_range, beta_range, FUN = gfunc.vec, x_data)

contour(x = alpha_range, 
        y = beta_range, 
        z = g, 
        xlab=expression(alpha),
        ylab=expression(beta),
        main=expression(paste("Proportional to ", pi, "(", alpha, ",", beta, "|x)")), 
        xlim=range(alpha_range), 
        ylim=range(beta_range), 
        col="blue",
        nlevels = 10)
```

## (iii) Values of $\alpha$, $\beta$ that maximises $\pi$($\alpha$,$\beta$|x)

The appropriate values are **2.5593** for alpha and **0.8415** for beta.

```{r maximise, echo=TRUE}
# A function that returns a value proportional to the negative log of the posterior
negLogPost = function(params, x)
{
    alpha = params[1]
    beta  = params[2]
    return( - log( dunif(alpha, 0, 5) * dgamma(beta, 4, 8) * L(alpha, beta, x) ) )
}

estimates = optim( par = c(2.5, 0.5), 
                   fn = negLogPost, 
                   x = x_data,
                   lower = c(0.0001, 0.0001),
                   upper = c(5, Inf),
                   method = "L-BFGS-B")$par
names(estimates) = c('alpha', 'beta')
```

```{r tableForEstimates}
library(knitr)
library(kableExtra)

headings = c('$\\alpha $', '$\\beta$')

estimates_mtx <- matrix(c(round(estimates, 4)), ncol = 2)
colnames(estimates_mtx) <- c(headings)

kable(estimates_mtx, format = 'latex', align="c", escape = F, 
      caption = "Values of $\\alpha$ and $\\beta$ that maximises  $\\pi$($\\alpha$,$\\beta$|x)") %>% 
  kable_styling(latex_options = c("hold_position"))  
```

## (iv) Function to obtain marginal distribution of $\alpha|x$ using numerical integration

We want to obtain  $\pi(\alpha| \pmb x)$ up to a proportionality constant, that is, $$\pi(\alpha| \pmb x) \propto \int_{\pmb \beta} \pi(\alpha) \pi(\pmb \beta) L(\pmb \alpha, \pmb \beta, \pmb x)d \pmb \beta.$$

```{r alpham}
require(cubature)

gfunc.int = function(params, x)
{
    alpha = params[1]
    beta  = params[2]
    return( dunif(alpha, min = 0, max = 5) * dgamma(beta, shape = 4, rate = 8) * L(alpha, beta, x) )
}

m_x = adaptIntegrate(gfunc.int, lowerLimit = c(0.0001, 0.0001), upperLimit = c(5, 2), x = x_data)$integral


gfunc.int_beta =  Vectorize(gfunc, vectorize.args = c("beta"))
alpham = function(alpha, x)
{
   numerator   = integrate(gfunc.int_beta, lower = 0.0001, upper = 2, alpha = alpha, x = x)$value
   denominator = m_x
   return( numerator / denominator  )
}
alpham.vec = Vectorize(alpham, vectorize.args = "alpha")

n = 1000
x = seq(from = 0, to = 5, length.out = n)
y = NULL

for(i in 1:n)
{
   y[i] = alpham(x[i], x_data)
}

plot(y ~ x, 
     col  = 'red',
     lty  = 1,
     type = 'l',
     xlab = expression(alpha), 
     ylab = "",
     main = expression(paste("Proportional to ", pi, "(", alpha, "|x)")))
```


## (v) Estimates of the posterior mean and variance of $\alpha$

```{r estimates}
MeanIntegrand = function(alpha, x)
{
  return( alpha * alpham(alpha, x) )
}
MeanIntegrand.vec = Vectorize(MeanIntegrand, vectorize.args = c("alpha"))
mean = integrate(MeanIntegrand.vec, lower = 2, upper = 3, x = x_data)$value

VarIntegrand = function(alpha, x)
{
  return( alpha^2 * alpham(alpha, x) )
}
VarIntegrand.vec = Vectorize(VarIntegrand, vectorize.args = c("alpha"))
xx = integrate(VarIntegrand.vec, lower = 2, upper = 3, x = x_data)$value
variance =  xx - mean^2

c('Mean' = mean,
  'Variance' = variance)
```

## (vi) Acceptance-rejection method for inference on $\alpha$

```{r plotAR}
plot(y ~ x, 
     col  = 'red',
     lty  = 1,
     type = 'l',
     xlab = expression(alpha), 
     ylab = "",
     main = expression(paste("Proportional to ", pi, "(", alpha, "|x)")))

set.seed(1)
n = 1000
xx <- runif(n, min=2, max=3)
yy <- runif(n, min=0, max=5)
#points(xx, yy, pch = 19, cex = 0.5, col="blue")

retained_ids = yy <= alpham.vec(xx, x_data)
points(xx[retained_ids], yy[retained_ids], pch = 19, cex = 0.2, col="blue")
```

```{r ar}
# Provides posterior draws (of at least 20 000) from alpha|x
set.seed(1)

ar = function(n = 1000)
{
  xx <- runif(n, min=2, max=3)
  yy <- runif(n, min=0, max=5)
  retained_ids = yy <= alpham.vec(xx, x_data)
  
  draws = xx[retained_ids]
  return(draws)
}

draws = ar()
length(draws)
c("mean" = mean(draws),
  "variance" = var(draws))
```

