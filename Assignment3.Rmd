---
title: "Assignment 3: Bayesian Analysis  \nLighthouse Problem\n"
author: "Shane Weisz (WSZSHA001)"
date: "19/09/2019"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
header-includes: \usepackage{float} \makeatletter\renewcommand*{\fps@figure}{H}\makeatother
---
This assignment involves the use of Bayesian Analysis methods to solve 'The Lighthouse Problem', where we attempt to draw inference on the coordinates of a lighthouse at an unknown location in the sea given a series of flashes emitted by the lighthouse that are observed at different points on the coastline.

# Questions
## (i) Derivation of posterior distribution of $\alpha,\beta| \pmb x$

We want to derive the posterior distribution of $\alpha,\beta|\boldsymbol{x}$, which can be expressed as:
$$\pi(\alpha,\beta|\boldsymbol{x}) = \frac{\pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x})}{m(\boldsymbol{x})}= \frac{g(\alpha,\beta;\boldsymbol{x})}{m(\boldsymbol{x})},$$ where 
$g(\alpha,\beta;\boldsymbol{x})=\pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x})$.

We proceed by calculating each of these components individually:

#### Prior: $\pi(\alpha,\beta)$

From the context of the problem, we can make the assumption that $\alpha$ and $\beta$ are independent. As such, we can obtain our prior distribution from $$\pi(\alpha,\beta)=\pi(\alpha)\pi(\beta)$$. 

We are given that $\alpha \sim \text{U}(0,5)$ and $\beta \sim \text{Gamma}(4,8)$, and so substituting the appropriate density functions yields our **prior distribution**: $$\pi(\alpha,\beta)=\pi(\alpha)\pi(\beta) = \frac{1}{5}\frac{8^4 \beta^3 e^{-8\beta}}{\Gamma(4)}=\frac{2048\beta^3 e^{-8\beta}}{15}$$

#### Likelihood: $\text{L}(\alpha,\beta$;$\boldsymbol{x}$)

We first note that we calculate the likelihood as follows:
$$\text{L}(\alpha,\beta, \boldsymbol{x})=\prod_{i=1}^{200} f(x_i|\alpha,\beta)$$

We thus need to calculate the density function for the data, $f(x_i|\alpha,\beta)$. 
So let $\theta_i$ be the angle of inclination of the line joining the lighthouse to the point on the coastline where the $i^{th}$ emission was recorded. It follows that $\tan(\theta_i)=\frac{x_i-\alpha}{\beta}$ and hence that $\theta_l=-\arctan(\frac{\alpha}{\beta})<\theta_k<\arctan(\frac{5-\alpha}{\beta})=\theta_u$.

Now the problem definition allows us to make the assumption that $\theta_i \sim\text{U}(\theta_l,\theta_u)$, which yields the p.d.f. of $\theta_i$ as $\pi(\theta_i)=\frac{1}{\theta_u-\theta_l}=\frac{1}{\text{A}(\alpha,\beta)}$, where we define $\text{A}(\alpha,\beta) = \theta_u-\theta_l$.

Applying an appropriate univariate transformation, we obtain that $f(x_i|\alpha,\beta)=\frac{1}{\text{A}(\alpha,\beta)}\begin{vmatrix}\frac{d \theta_i}{d {x_i}}\end{vmatrix}$ where $\frac{d \theta_i}{d {x_i}}=\frac{d}{d {x_i}}\arctan(\frac{x_i-\alpha}{\beta})=\frac{\beta}{\beta^2+(x_k-\alpha)^2}.$
Since $\beta>0$, we get that $\frac{\beta}{\beta^2+(x_k-\alpha)^2}>0$, and so  $f(x_i|\alpha,\beta)=\frac{1}{\text{A}(\alpha,\beta)}\cdot\frac{\beta}{\beta^2+(x_i-\alpha)^2}$.

Substituting into the above formula for the likelihood gives us our **likelihood** function:
$$\text{L}(\alpha,\beta, \boldsymbol{x})=\prod_{i=1}^{200} f(x_i|\alpha,\beta) = \prod_{i=1}^{200} \frac{1}{\text{A}(\alpha,\beta)}\cdot\frac{\beta}{\beta^2+(x_i-\alpha)^2}$$

#### Predictive pdf of x: $m(\boldsymbol{x})$

By the Law of Total Probability, we have that $$m(\boldsymbol{x})=\int_{0}^5 \int_{0}^{\infty} \pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x}) d\beta d\alpha$$ where $\pi(\alpha,\beta)=\frac{2048\beta^3 e^{-8\beta}}{15}$ and $\text{L}(\alpha,\beta, \boldsymbol{x})= \prod_{i=1}^{200} \frac{1}{\text{A}(\alpha,\beta)}\cdot\frac{\beta}{\beta^2+(x_i-\alpha)^2}$, as derived above.

#### Resulting posterior distribution of $\alpha,\beta| \pmb x$

Combining the above expressions, we thus get that $$\pi(\alpha,\beta|\boldsymbol{x}) = \frac{g(\alpha,\beta;\boldsymbol{x})}{m(\boldsymbol{x})},$$ where \label{sec:g}
$$ g(\alpha,\beta;\boldsymbol{x})=\pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x}),$$
$$\pi(\alpha,\beta)=\frac{2048\beta^3 e^{-8\beta}}{15},$$
,$$\text{L}(\alpha,\beta, \boldsymbol{x})= \prod_{i=1}^{200} \frac{1}{\text{A}(\alpha,\beta)}\cdot\frac{\beta}{\beta^2+(x_i-\alpha)^2},$$
$$\text{A}(\alpha,\beta) = \arctan(\frac{5-\alpha}{\beta}) + \arctan(\frac{\alpha}{\beta}),$$
and finally $$m(\boldsymbol{x})=\int_{0}^5 \int_{0}^{\infty} \pi(\alpha,\beta) \text{L}(\alpha,\beta;\boldsymbol{x}) d\beta d\alpha.$$

## (ii) Function to calculate g($\alpha$,$\beta$;x) and obtain contour plot

```{r loadData, include=FALSE}
load("~/Documents/UCT/3rd Year/STA3043S/Assignments/Assignment3/Assignment3Data2019.RData")
x_data = Data['wszsha001',]
```

The R function `gfunc` (see \hyperref[sec:appendix]{\textbf{Appendix}}) was written to calculate g($\alpha,\beta; \pmb x$), using the expression derived in  \hyperref[sec:g]{\textbf{Question (i)}} above.

```{r gfunc, echo=FALSE}

# ================== Question (ii) =====================

# A(alpha, beta) is defined as the difference between the upper and lower bounds for theta
A = function(alpha, beta)
{
   return( (atan((5 - alpha) / beta)) - (-atan(alpha / beta)) )
}

# Returns the likelihood function for alpha and beta given an observed data vector x
L = function(alpha, beta, x)
{
   return( prod( (1 / A(alpha, beta)) * beta / (beta ^ 2 + (x - alpha)^2)) )
}

# Returns g(alpha,beta;x) - the numerator of the posterior
gfunc = function(alpha, beta, x)
{
    prior_alpha = dunif(alpha, min = 0, max = 5)
    prior_beta  = dgamma(beta, shape = 4, rate = 8)
    return( prior_alpha * prior_beta * L(alpha, beta, x) )
}
gfunc.vec = Vectorize(gfunc, vectorize.args = c("alpha","beta"))

```

We then create a sequence of $\alpha$ values ranging between 0 and 5, and a sequence of $\beta$ values between 0 and 1.5. The function described above is then evaluated at each $\alpha$ and $\beta$ combination (i.e. we evaluate g($\alpha,\beta; \pmb x$) at each combination) to obtain the contour plot proportional to $\pi(\alpha,\beta| \pmb x)$ below.

```{r contourPlot, echo=FALSE, fig.cap="Contour Plot"}
n = 100
alpha_range = seq(from = 0, to = 5, length.out = n)
beta_range  = seq(from = 0, to = 1.5, length.out = n)
g = outer(alpha_range, beta_range, FUN = gfunc.vec, x_data)

contour(x = alpha_range, 
        y = beta_range, 
        z = g, 
        xlab=expression(alpha),
        ylab=expression(beta),
        main=expression(paste("Proportional to ", pi, "(", alpha, ",", beta, "|x)")), 
        xlim=range(alpha_range), 
        ylim=range(beta_range), 
        col="blue",
        nlevels = 10)
```

Notice how highly concentrated the plot is around the point $\alpha \approx 2.6$ and $\beta \approx 0.8$. This corresponds to a significant 'spike' in the three dimensional surface around this point. We will continue our discussion of this plot in \hyperref[sec:iii]{\textbf{Question (iii)}} below.

```{r eval=FALSE, include=FALSE}
library(plotly)
plot_ly(x = alpha_range, 
        y = beta_range, 
        z = g) %>% add_surface()
```


## (iii) Values of $\alpha$, $\beta$ that maximises $\pi$($\alpha$,$\beta$|x)

\label{sec:iii}

We now want to obtain the values of $\alpha$, $\beta$ that maximises $\pi$($\alpha$,$\beta | \pmb x$). This corresponds to the point inside the innermost contour in the contour plot above. Note that $m(\pmb x)$ is a constant, and that the log function is a mononotonically increasing function. Thus the values that maximise $\pi$($\alpha$,$\beta | \pmb x$) are the same as the values that maximise $\text{log}(g(\alpha,\beta; \pmb x))$.

```{r maximise, echo=FALSE}

# ================== Question (iii) =====================

# A function that returns a value proportional to the negative log of the posterior
negLogPost = function(params, x)
{
    alpha = params[1]
    beta  = params[2]
    prior_alpha = dunif(alpha, min = 0, max = 5)
    prior_beta  = dgamma(beta, shape = 4, rate = 8)
    return( - log( prior_alpha * prior_beta * L(alpha, beta, x) ) )
}

estimates = optim( par = c(2.5, 0.5), 
                   fn = negLogPost, 
                   x = x_data,
                   lower = c(0.0001, 0.0001),
                   upper = c(5, Inf),
                   method = "L-BFGS-B")$par
names(estimates) = c('alpha', 'beta')
```

We then use a numerical optimization technique in R to obtain the resulting maximising values of $\alpha$, $\beta$ below.
 
```{r tableForEstimates, echo=FALSE}
library(knitr)
library(kableExtra)

headings = c('$\\alpha $', '$\\beta$')

estimates_mtx <- matrix(c(round(estimates, 4)), ncol = 2)
colnames(estimates_mtx) <- c(headings)

kable(estimates_mtx, format = 'latex', align="c", escape = F, 
      caption = "Values of $\\alpha$ and $\\beta$ that maximises  $\\pi$($\\alpha$,$\\beta$|x)") %>% 
  kable_styling(latex_options = c("hold_position"))  
```

## (iv) Function to obtain marginal distribution of $\alpha|\pmb x$ using numerical integration

The function `alpham` below uses numerical integration to obtain the marginal distribution of $\alpha|x$,  given by $$\pi(\alpha| \pmb x) = \frac{ \int_{\pmb \beta} \pi(\alpha) \pi(\pmb \beta) L(\pmb \alpha, \pmb \beta, \pmb x)d \pmb \beta.}{m(\pmb x)}.$$

```{r alpham, echo=FALSE}

# ================== Question (iv) =====================

library(cubature)

gfunc.int = function(params, x)
{
    alpha = params[1]
    beta  = params[2]
    prior_alpha = dunif(alpha, min = 0, max = 5)
    prior_beta  = dgamma(beta, shape = 4, rate = 8)
    return( prior_alpha * prior_beta * L(alpha, beta, x) )
}

m_x = adaptIntegrate(gfunc.int, 
                     lowerLimit = c(0.0001, 0.0001), 
                     upperLimit = c(5, 1.5), 
                     x = x_data)$integral


gfunc.int_beta =  Vectorize(gfunc, vectorize.args = c("beta"))
alpham = function(alpha, x)
{
   numerator   = integrate(gfunc.int_beta, 
                           lower = 0.0001, 
                           upper = 1.5, 
                           alpha = alpha, 
                           x = x)$value
   denominator = m_x
   return( numerator / denominator  )
}
alpham.vec = Vectorize(alpham, vectorize.args = "alpha")
```

```{r plotDbn, echo=FALSE, fig.cap = "Density function of the marginal distribution of $\\alpha| \\pmb x$"}
n = 1000
x = seq(from = 1.5, to = 3.5, length.out = n)
y = NULL
for(i in 1:n)
{
   y[i] = alpham(x[i], x_data)
}

plot(y ~ x, 
     col  = 'red',
     lty  = 1,
     type = 'l',
     xlab = expression(alpha), 
     ylab = "",
     main = expression(paste(pi, "(", alpha, "|x)")))
```

## (v) Estimates of the posterior mean and variance of $\alpha$

The below code is used to provide estimates for the posterior mean and variance of $\alpha.$

```{r estimates, echo=FALSE}

# ================== Question (v) =====================

MeanIntegrand = function(alpha, x)
{
  return( alpha * alpham(alpha, x) )
}
MeanIntegrand.vec = Vectorize(MeanIntegrand, vectorize.args = c("alpha"))
mean = integrate(MeanIntegrand.vec, lower = 2, upper = 3, x = x_data)$value

VarIntegrand = function(alpha, x)
{
  return( alpha^2 * alpham(alpha, x) )
}
VarIntegrand.vec = Vectorize(VarIntegrand, vectorize.args = c("alpha"))
x_sq = integrate(VarIntegrand.vec, lower = 2, upper = 3, x = x_data)$value
variance =  x_sq - mean^2

headings = c('Mean', 'Variance') 
estimates_mtx <- matrix(c(round(mean, 4), round(variance, 4)), ncol = 2)
colnames(estimates_mtx) <- c(headings)

kable(estimates_mtx, format = 'latex', align="c", escape = F, 
      caption = "Estimates of the posterior mean and variance of $\\alpha$") %>% 
  kable_styling(latex_options = c("hold_position")) 
```

## (vi) Acceptance-rejection method for inference on $\alpha$

We use the acceptance-rejection method to provide draws from $\alpha| \pmb x$, and then use these draws to provide estimates of the posterior mean and variance of $\alpha.$

```{r plotAR, echo=FALSE}

# ================== Question (vi) =====================

# plot(y ~ x, 
#      col  = 'red',
#      lty  = 1,
#      type = 'l',
#      xlab = expression(alpha), 
#      ylab = "",
#      main = expression(paste(pi, "(", alpha, "|x)")))

set.seed(2019)
n = 1000
xx <- runif(n, min=2.25, max=2.85)
yy <- runif(n, min=0, max=4.6) # since max(y) = 4.579861 where y has the density values 

retained_ids = yy <= alpham.vec(xx, x_data)
# points(xx[retained_ids], yy[retained_ids], pch = 19, cex = 0.2, col="blue")
```

```{r ar, echo=FALSE}
# Provides posterior draws (of at least 20 000) from alpha|x
set.seed(2019)

ar = function(num_to_accept = 20000)
{
  count = 0
  draws = NULL
  while(count <= num_to_accept)
  {
    x <- runif(1, min=2.25, max=2.85)
    y <- runif(1, min=0, max=4.6)
    if(y < alpham(x, x_data))
    {
       draws[count] = x
       count = count + 1
    }
  }
  return(draws)
}

draws = ar()
# length(draws)

headings = c('Mean', 'Variance') 
estimates_mtx <- matrix(c(round(mean(draws), 4), round(var(draws), 4)), ncol = 2)
colnames(estimates_mtx) <- c(headings)
kable(estimates_mtx, format = 'latex', align="c", escape = F, 
      caption = "Estimates of the posterior mean and variance of $\\alpha$ using Acceptance-Rejection") %>% 
  kable_styling(latex_options = c("hold_position")) 
```

Notice that these estimates are very similar to the estimates obtained in (v).

**Include histogram - check this corresponds with above**

# Appendix
\label{sec:appendix}

```{r ref.label = knitr::all_labels(), echo=TRUE, eval=FALSE}

```